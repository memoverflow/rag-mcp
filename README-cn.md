# RAG-MCP: 基于多通道原则的检索增强生成

## 项目概述

RAG-MCP 是一个将检索增强生成（RAG）与多通道原则（MCP）相结合的系统，旨在优化大型语言模型（LLMs）与工具之间的交互体验。该系统智能地检索相关工具和知识，显著提高了令牌效率、响应时间和准确性。

本实现基于["RAG-MCP：通过检索增强生成缓解LLM工具选择中的提示膨胀"](https://arxiv.org/html/2505.03275v1)论文中描述的方法，该方法解决了LLMs访问众多工具时面临的"提示膨胀"挑战。

## 研究基础

如研究论文所述，大型语言模型在面对众多外部工具时面临重大挑战：

1. **提示膨胀**：在提示中包含所有工具描述会消耗上下文窗口的大部分空间，留给实际推理的空间较少。
2. **决策开销**：面对众多工具选项（通常功能重叠），模型难以选择合适的工具。
3. **性能下降**：随着工具数量增加，选择准确性显著下降。

我们的实现遵循论文中提出的三步流程：

1. **工具索引**：MCP工具模式存储在具有语义嵌入的知识库中
2. **基于查询的检索**：当用户提交查询时，系统仅检索最相关的工具
3. **聚焦的LLM处理**：LLM接收仅包含相关工具的精简提示，实现更准确的工具选择

## 核心功能

- **知识库驱动的工具选择**：基于用户查询智能检索相关工具，而非提供所有可用工具
- **多通道交互**：支持跨文件系统操作、知识库查询和API集成的全面交互
- **高效令牌使用**：通过仅提供相关工具，显著减少令牌消耗（平均减少30%）
- **灵活配置**：支持环境变量配置，易于适应不同的部署环境
- **全面测试**：包含详细的测试套件，用于性能比较和验证

## 系统架构

```
rag-mcp/
├── chat/                   # 核心聊天和工具集成
│   ├── bedrock_client.py   # AWS Bedrock API客户端
│   ├── chat_manager.py     # 对话管理和工具协调
│   ├── config.py           # 配置管理
│   ├── knowledge_base.py   # 知识库集成
│   ├── mcp_client.py       # MCP工具客户端
│   └── cli.py              # 命令行界面
├── test/                   # 全面测试系统
│   ├── comprehensive_mcp_comparison_test.py  # 主要比较测试
│   ├── html_report_generator.py              # HTML报告生成
│   ├── run_complete_test.py                  # 测试运行器
│   └── [其他测试文件]
└── .env                    # 环境变量配置（私有）
```

## 主要组件

### 1. 聊天管理

`ChatManager`类协调LLM对话、工具使用和知识库检索，提供流畅的用户交互体验。它处理消息处理、工具选择和对话历史管理。

### 2. 工具集成

系统集成各种工具功能：
- 文件系统操作（读取、写入、搜索文件）
- 目录管理
- 知识库查询
- API集成

可用的MCP工具包括文件管理、目录操作和搜索功能。

### 3. 知识库系统

使用AWS Bedrock知识库服务通过向量搜索检索相关工具和知识。知识库既是数据源，也是工具选择机制。

这是论文中描述的RAG-MCP方法的关键实现。系统不是一次性向模型展示所有工具，而是：

1. 将所有工具定义和模式嵌入到向量数据库中
2. 使用用户的查询检索最语义相关的工具
3. 仅向LLM展示这些工具，大幅减少上下文使用量

### 4. 配置管理

通过环境变量和配置类提供灵活设置：
- AWS凭证和区域
- Bedrock模型参数
- 知识库ID
- 聊天选项
- MCP工具设置

## RAG-MCP方法实现

RAG-MCP核心方法通过以下组件实现：

### 工具检索机制

`knowledge_base.py`模块实现了构成RAG-MCP方法核心的语义检索系统。当用户提交查询时：

1. 使用与知识库相同的嵌入模型对查询进行向量化
2. 相似度搜索检索最相关的工具定义
3. 仅将这些相关工具包含在提供给LLM的提示中

这种方法允许系统高效处理大量潜在工具（MCP服务器），而不会使模型的上下文窗口过载。

### 工具选择改进

如我们的测试所示（与论文发现一致），这种基于检索的方法：

- 将提示令牌减少约30-50%
- 将工具选择准确率从~15%（包含所有工具的基线）提高到~40-45%（使用RAG-MCP）
- 即使随着可用工具数量增加，仍能保持高性能

### 性能扩展

系统设计为随着工具添加而高效扩展：
- 可以将新工具添加到知识库中，无需重新训练
- 即使有数百个潜在工具，检索精度仍然很高
- 随着工具数量增加，令牌效率提升最为显著

## 测试和评估系统

该项目包括一个全面的测试套件，用于比较RAG-MCP与完整MCP工具的性能：

- **令牌效率**：测量令牌使用减少量，平均节省约30%
- **响应时间**：RAG-MCP通常比完整MCP更快
- **准确性**：工具选择准确性和响应质量
- **成功率**：成功处理查询的百分比

### 测试报告

系统生成详细的HTML报告，包括：
- 交互式图表和可视化
- 关键指标卡片
- 详细分析部分
- 基于测试结果的智能建议

## 使用方法

### 环境设置

1. 在项目根目录创建`.env`文件：

```bash
# AWS配置
AWS_REGION=区域
AWS_ACCESS_KEY_ID=您的访问密钥
AWS_SECRET_ACCESS_KEY=您的秘密密钥

# Bedrock配置
BEDROCK_MODEL_ID=anthropic.claude-3-sonnet-20240229-v1:0
BEDROCK_MAX_TOKENS=4096
BEDROCK_TEMPERATURE=0.7

# 知识库配置
KB_KNOWLEDGE_BASE_ID=您的知识库ID
KB_DATA_SOURCE_ID=您的数据源ID
KB_S3_BUCKET=您的S3存储桶

# 聊天配置
CHAT_MAX_TOOL_ROUNDS=15
CHAT_ENABLE_AUTO_TOOLS=true

# MCP配置
MCP_COMMAND=您的MCP命令
MCP_ARGS=您的MCP参数
```

2. 安装依赖

使用conda环境：
```bash
conda env create -f environment.yml
conda activate rag-mcp
```

### 运行测试

```bash
# 运行完整测试并生成HTML报告
python test/run_complete_test.py

# 运行演示测试（3个查询）
python test/run_complete_test.py --demo

# 指定测试查询数量
python test/run_complete_test.py --queries 5

# 测试完成后自动清理临时文件
python test/run_complete_test.py --demo --cleanup
```

### 使用命令行界面

```bash
# 启动聊天界面
python -m chat.cli

# 指定自定义配置
python -m chat.cli --kb-id 自定义知识库ID --model-id 自定义模型ID
```

## 性能基准

基于文件系统操作的全面测试，RAG-MCP相比传统的完整MCP展示了显著改进：

| 指标 | RAG-MCP | 完整MCP | 改进 |
|--------|---------|----------|-------------|
| 平均令牌使用量 | 1,670 | 6,630 | 减少74.8% |
| 平均响应时间 | 6.71秒 | 17.69秒 | 快62.1% |
| 成功率 | 100% | 88.9% | +11.1% |
| 工具选择准确率 | 61.1% | 66.7% | -5.6% |

### 测试关键发现

1. **显著的令牌效率**：RAG-MCP将令牌使用量减少了近75%，大大超出了我们最初30-50%的预期。这直接转化为更低的API成本和更快的处理速度。

2. **显著的速度提升**：RAG-MCP的响应时间比完整MCP快约62%，最复杂的查询显示最大改进（多工具查询快至75%）。

3. **更高的成功率**：RAG-MCP在完成请求操作方面显示100%的成功率，相比之下完整MCP为88.9%，表明对最终用户更高的可靠性。

4. **工具准确性权衡**：虽然完整MCP显示略好的工具选择准确性（+5.6%），但这一优势被更慢的响应时间和显著更高的令牌消耗所抵消。准确性差异主要出现在复杂的多工具场景中。

5. **特定查询性能**：
   - 对于简单查询（文件列表、读取）：RAG-MCP实现可比的准确性，同时令牌减少45-57%
   - 对于复杂查询（搜索、多文件操作）：RAG-MCP实现70-84%的令牌减少，准确性适度权衡
   - 对于目录操作：RAG-MCP实现75-80%的令牌减少，具有竞争力的准确性

这些结果与RAG-MCP论文中的发现一致，该论文报告：
- 在某些情况下令牌减少超过50%
- 工具选择准确率从13.62%（基线）提高到43.13%（使用RAG-MCP）
- 更高效的提示利用（1084令牌 vs 基线的2133令牌）

## 技术栈

- **AWS Bedrock**：LLM和知识库服务
- **Python**：主要开发语言
- **Conda**：环境管理
- **Chart.js**：报告可视化
- **Async I/O**：异步操作

## 安全最佳实践

1. **永远不要将`.env`文件**提交到版本控制（它在.gitignore中）
2. **使用环境变量**进行所有敏感配置
3. **在AWS基础设施上运行时使用IAM角色**
4. **定期轮换凭证**
5. **对AWS权限使用最小权限原则**

## 特殊命令（CLI）

命令行界面支持以下特殊命令：

- `q`或`exit`：退出聊天
- `clear`：清除对话历史
- `history`：查看对话历史
- `tools`：查看所有可用工具
- `sync`：将工具同步到知识库
- `help`：显示帮助信息

## 可扩展性

这种架构设计具有良好的可扩展性：

- 可以轻松添加新的客户端类型
- 支持插件式工具集成
- 配置系统支持动态扩展
- 异常处理机制可定制

## 故障排除

### 常见问题

1. **MCP连接失败**
   ```
   解决方案：检查MCP服务器配置和网络连接
   ```

2. **知识库查询失败**
   ```
   解决方案：验证AWS凭证和知识库配置
   ```

3. **令牌统计不准确**
   ```
   解决方案：确保Bedrock客户端配置正确
   ```

4. **文件已存在错误**
   ```
   解决方案：系统自动生成唯一文件名。如果问题持续，运行清理脚本
   python test/cleanup_test_files.py --execute
   ```

## 未来工作

如论文所述，未来工作的几个方向包括：

1. **层次检索**：为极大的工具集实现嵌套检索机制
2. **自适应选择**：根据查询复杂性动态调整检索的工具数量
3. **多工具工作流**：增强系统以支持复杂任务的工具操作序列
4. **准确性改进**：完善知识检索系统以提高工具选择准确性，特别是对于复杂的多工具操作
5. **上下文窗口优化**：进一步研究优化上下文窗口使用，以最大化效率和准确性

## 结论

RAG-MCP在减少令牌使用（74.8%）和改善响应时间（快62.1%）方面表现出色，对准确性的影响最小。该方法随着工具数量增加而有效扩展，使其成为对效率和可扩展性至关重要的生产环境的理想解决方案。虽然在复杂操作的工具选择准确性方面存在轻微权衡，但在成本节约、速度和可靠性方面的整体好处使RAG-MCP成为具有广泛工具集成需求的生产LLM系统的推荐方法。

## 许可和贡献

RAG-MCP是一个内部研究项目，贡献必须遵循贡献指南。

---

© 2024 RAG-MCP团队 